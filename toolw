#!/usr/bin/env python3
import argparse
import hashlib
import json
import netrc
import os
import platform
import random
import shutil
import string
import subprocess
import sys
import tarfile
import urllib.parse
import urllib.request
import urllib.error
import zipfile

sys.stdout = sys.stderr

VERSION = "1.0.0"
LOCKFILE_NAME = "toolw.lock.json"


def log(msg):
    print(f"[toolw] {msg}", file=sys.stderr)


def error(msg):
    print(f"[toolw] ERROR: {msg}", file=sys.stderr)
    sys.exit(1)


class AuthorizationHeaderHandler(urllib.request.BaseHandler):
    """Injects custom Authorization headers into HTTP/HTTPS requests."""

    def __init__(self, auth_value):
        self.auth_value = auth_value

    def http_request(self, request):
        request.add_header('Authorization', self.auth_value)
        return request

    https_request = http_request


def _invoke_credential_helper(url):
    """
    Invoke TOOLW_CREDENTIAL_HELPER executable to get Authorization header.

    Returns:
        Authorization header value (e.g., "Bearer token") or None if not configured

    Raises:
        SystemExit via error() if helper is configured but fails
    """
    helper_path = os.environ.get('TOOLW_CREDENTIAL_HELPER')
    if not helper_path:
        return None

    # Validate helper executable
    if not os.path.isfile(helper_path):
        error(f"TOOLW_CREDENTIAL_HELPER not found: {helper_path}")
    if not os.access(helper_path, os.X_OK):
        error(f"TOOLW_CREDENTIAL_HELPER is not executable: {helper_path}")

    # Invoke helper with URL as argument
    try:
        result = subprocess.run(
            [helper_path, url],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode != 0:
            stderr = result.stderr.strip() or '(no error message)'
            error(f"Credential helper failed (exit {result.returncode}): {stderr}")

        auth_value = result.stdout.strip()
        if not auth_value:
            error("Credential helper returned empty authorization value")

        return auth_value

    except subprocess.TimeoutExpired:
        error("Credential helper timed out after 10 seconds")
    except Exception as e:
        error(f"Failed to execute credential helper: {e}")


def _create_netrc_handler(url):
    """
    Create HTTPBasicAuthHandler with credentials from .netrc file.

    Returns:
        HTTPBasicAuthHandler (may have empty password manager if .netrc unavailable)
    """
    password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()

    try:
        netrc_auth = netrc.netrc()
        hostname = urllib.parse.urlparse(url).hostname
        if hostname:
            auth_info = netrc_auth.authenticators(hostname)
            if auth_info:
                login, _, password = auth_info
                password_mgr.add_password(None, url, login, password)
    except:
        # .netrc not available or no matching entry - continue without auth
        pass

    return urllib.request.HTTPBasicAuthHandler(password_mgr)


def create_authenticated_opener(url):
    """
    Create urllib opener with appropriate authentication for the given URL.

    Priority:
        1. TOOLW_CREDENTIAL_HELPER (if set)
        2. .netrc authentication (fallback)

    Args:
        url: Download URL

    Returns:
        Configured urllib opener ready for requests
    """
    # Try credential helper first
    auth_value = _invoke_credential_helper(url)
    if auth_value:
        handler = AuthorizationHeaderHandler(auth_value)
        return urllib.request.build_opener(handler)

    # Fall back to .netrc
    handler = _create_netrc_handler(url)
    return urllib.request.build_opener(handler)


def parse_arguments():
    parser = argparse.ArgumentParser(prog='toolw', add_help=False)
    parser.add_argument('--help', action='store_true')
    parser.add_argument('--version', action='store_true')
    parser.add_argument('--clean', action='store_true')
    parser.add_argument('-c', '--config')
    parser.add_argument('tool', nargs='?')
    parser.add_argument('args', nargs=argparse.REMAINDER)
    return parser.parse_known_args()


def print_help():
    """
    We disable ArgumentParser's built-in help (add_help=False) because:
    1. Help is context-sensitive: 'toolw --help' shows this message,
       but 'toolw <tool> --help' passes --help to the underlying tool
    2. ArgumentParser's built-in help would exit immediately, preventing
       passthrough to wrapped executables
    """
    print(f"""toolw version {VERSION}

USAGE:
    toolw [OPTIONS] <tool-name> [tool-args...]

OPTIONS:
    --help              Show this help message
    --version           Show version
    --clean             Clean cache
    -c, --config PATH   Path to lockfile

CACHE:
    ~/.cache/toolw/ (override with TOOLW_CACHE_DIR)
""", file=sys.stderr)


def determine_tool_name(args, script_path):
    script_name = os.path.basename(script_path)
    if script_name in ('toolw', 'toolw.py'):
        if not args.tool:
            error("No tool specified")
        return args.tool
    return script_name


def discover_lockfile(config_path, script_path):
    if config_path:
        if os.path.isfile(config_path):
            return config_path
        error(f"Lockfile not found: {config_path}")

    candidates = [
        os.path.join(os.path.dirname(os.path.abspath(script_path)), LOCKFILE_NAME),
        os.path.join(os.getcwd(), LOCKFILE_NAME)
    ]

    for path in candidates:
        if os.path.isfile(path):
            return path

    error(f"Could not find {LOCKFILE_NAME}")


def parse_lockfile(path):
    try:
        with open(path) as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        error(f"Invalid JSON: {e}")
    except OSError as e:
        error(f"Failed to read lockfile: {e}")


def detect_platform():
    system = platform.system().lower()
    os_map = {'darwin': 'macos', 'linux': 'linux', 'windows': 'windows'}
    if system not in os_map:
        error(f"Unsupported OS: {system}")

    machine = platform.machine().lower()
    if machine in ('x86_64', 'amd64', 'x64'):
        cpu = 'x86_64'
    elif machine in ('arm64', 'aarch64'):
        cpu = 'arm64'
    else:
        error(f"Unsupported CPU: {machine}")

    return os_map[system], cpu


def select_binary(tool_config, os_name, cpu_arch):
    if 'binaries' not in tool_config:
        error("Invalid tool config: missing 'binaries'")

    for binary in tool_config['binaries']:
        if binary.get('os') == os_name and binary.get('cpu') == cpu_arch:
            if binary['kind'] == 'archive' and 'file' not in binary:
                error("Archive missing 'file' field")
            return binary

    available = ', '.join(f"{b.get('os')}/{b.get('cpu')}" for b in tool_config['binaries'])
    error(f"No binary for {os_name}/{cpu_arch}. Available: {available}")


def get_cache_dir():
    # Check environment variable first
    toolw_cache = os.environ.get('TOOLW_CACHE_DIR')
    if toolw_cache is not None:
        return toolw_cache

    # Determine platform-specific cache directory
    system = platform.system().lower()

    if system == 'windows':
        base_dir = os.environ.get('LocalAppData')
        if base_dir is None:
            error("%LocalAppData% is not defined")
    elif system == 'darwin':
        base_dir = os.environ.get('HOME')
        if base_dir is None:
            error("$HOME is not defined")
        base_dir = os.path.join(base_dir, 'Library/Caches')
    elif system == 'linux':
        base_dir = os.environ.get('XDG_CACHE_HOME')
        if base_dir is None:
            base_dir = os.environ.get('HOME')
            if base_dir is None:
                error("neither $XDG_CACHE_HOME nor $HOME are defined")
            base_dir = os.path.join(base_dir, '.cache')
    else:
        error(f"Unsupported operating system '{system}'")

    return os.path.join(base_dir, 'toolw')


def get_cache_path(sha256, kind, archive_path=None):
    blob_dir = os.path.join(get_cache_dir(), 'blobs', sha256)
    if kind == 'file':
        return os.path.join(blob_dir, 'binary')
    return os.path.join(blob_dir, archive_path)


def clean_cache():
    cache_dir = get_cache_dir()
    if os.path.exists(cache_dir):
        shutil.rmtree(cache_dir)


def download_file(url, dest_path):
    """Download file from URL to destination path with authentication."""
    opener = create_authenticated_opener(url)

    try:
        log(f"Downloading {url}")
        with opener.open(url) as response, open(dest_path, 'wb') as f:
            shutil.copyfileobj(response, f)
    except urllib.error.URLError as e:
        error(f"Download failed: {e}")


def compute_sha256(path):
    h = hashlib.sha256()
    with open(path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            h.update(chunk)
    return h.hexdigest()


def extract_archive(archive_path, extract_dir):
    if archive_path.endswith(('.tar.gz', '.tgz')) or tarfile.is_tarfile(archive_path):
        with tarfile.open(archive_path, 'r:*') as tar:
            for member in tar.getmembers():
                if member.name.startswith('/') or '..' in member.name:
                    error(f"Unsafe path in archive: {member.name}")
            tar.extractall(extract_dir)
    elif archive_path.endswith('.zip') or zipfile.is_zipfile(archive_path):
        with zipfile.ZipFile(archive_path) as zf:
            for name in zf.namelist():
                if name.startswith('/') or '..' in name:
                    error(f"Unsafe path in archive: {name}")
            zf.extractall(extract_dir)
    else:
        error("Unknown archive format")


def download_and_cache(url, expected_sha256, kind, archive_file=None):
    final_path = get_cache_path(expected_sha256, kind, archive_file)
    if os.path.exists(final_path):
        return final_path

    suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
    staging_dir = os.path.join(get_cache_dir(), f'staging-{suffix}')
    os.makedirs(staging_dir, exist_ok=True)

    try:
        download_path = os.path.join(staging_dir, 'download')
        download_file(url, download_path)

        actual_sha256 = compute_sha256(download_path)
        if actual_sha256 != expected_sha256:
            error(f"Checksum mismatch: expected {expected_sha256}, got {actual_sha256}")

        if kind == 'file':
            os.makedirs(os.path.dirname(final_path), exist_ok=True)
            shutil.move(download_path, final_path)
            os.chmod(final_path, 0o755)
        else:
            extract_archive(download_path, staging_dir)
            if not os.path.exists(os.path.join(staging_dir, archive_file)):
                error(f"File not found in archive: {archive_file}")

            blob_dir = os.path.join(get_cache_dir(), 'blobs', expected_sha256)
            os.makedirs(blob_dir, exist_ok=True)

            top_level = archive_file.split('/')[0]
            shutil.move(os.path.join(staging_dir, top_level), os.path.join(blob_dir, top_level))
            os.chmod(final_path, 0o755)

        return final_path
    finally:
        shutil.rmtree(staging_dir, ignore_errors=True)


def main():
    args, unknown_args = parse_arguments()

    if args.version:
        print(f"toolw version {VERSION}")
        sys.exit(0)

    if args.clean:
        clean_cache()
        sys.exit(0)

    if args.help and not args.tool:
        print_help()
        sys.exit(0)

    tool_name = determine_tool_name(args, sys.argv[0])
    tool_args = args.args + unknown_args

    lockfile = parse_lockfile(discover_lockfile(args.config, sys.argv[0]))

    if tool_name not in lockfile:
        error(f"Tool '{tool_name}' not found. Available: {', '.join(lockfile.keys())}")

    os_name, cpu_arch = detect_platform()
    binary = select_binary(lockfile[tool_name], os_name, cpu_arch)

    archive_file = binary.get('file') if binary['kind'] == 'archive' else None
    tool_path = download_and_cache(binary['url'], binary['sha256'], binary['kind'], archive_file)

    os.execv(tool_path, [tool_path] + tool_args)


if __name__ == '__main__':
    main()
